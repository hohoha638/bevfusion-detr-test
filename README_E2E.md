# BEVFusion ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥ç³»ç»Ÿ ğŸš—ğŸ’¨

<div align="center">

**å®Œæ•´çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥è§£å†³æ–¹æ¡ˆ**

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-green.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-red.svg)](https://pytorch.org/)

[å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) | [åŠŸèƒ½ç‰¹æ€§](#-åŠŸèƒ½ç‰¹æ€§) | [æ€§èƒ½](#-æ€§èƒ½) | [æ–‡æ¡£](#-æ–‡æ¡£)

</div>

---

## ğŸ¯ é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å°†BEVFusionæ‰©å±•ä¸º**å®Œæ•´çš„ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥ç³»ç»Ÿ**ï¼Œåœ¨å•ä¸ªç»Ÿä¸€æ¨¡å‹ä¸­å®ç°ï¼š

| ä»»åŠ¡ | åŠŸèƒ½ | è¾“å‡º |
|------|------|------|
| ğŸ¯ **3Dç›®æ ‡æ£€æµ‹** | æ£€æµ‹å’Œå®šä½3Dç©ºé—´ä¸­çš„ç›®æ ‡ | 3Dè¾¹ç•Œæ¡†ã€ç±»åˆ«ã€ç½®ä¿¡åº¦ã€é€Ÿåº¦ |
| ğŸ—ºï¸ **è¯­ä¹‰åœ°å›¾** | ç”ŸæˆBEVè¯­ä¹‰åˆ†å‰²åœ°å›¾ | å¯è¡Œé©¶åŒºåŸŸã€è½¦é“çº¿ã€äººè¡Œé“ç­‰ |
| ğŸ¬ **å¤šç›®æ ‡è·Ÿè¸ª** | è·¨å¸§å…³è”å’Œè·Ÿè¸ªç›®æ ‡ | ç›®æ ‡IDã€è·Ÿè¸ªå†å² |
| ğŸ”® **è½¨è¿¹é¢„æµ‹** | é¢„æµ‹ç›®æ ‡æœªæ¥è¿åŠ¨è½¨è¿¹ | æœªæ¥6å¸§çš„ä½ç½®é¢„æµ‹ |

---

## âœ¨ åŠŸèƒ½ç‰¹æ€§

### ğŸ”‘ æ ¸å¿ƒåˆ›æ–°

- **ç»Ÿä¸€çš„å¤šä»»åŠ¡æ¶æ„**: å•ä¸ªTransformerå¤„ç†æ‰€æœ‰æ„ŸçŸ¥ä»»åŠ¡
- **Query-basedè®¾è®¡**: ç«¯åˆ°ç«¯å­¦ä¹ ï¼Œæ— éœ€æ‰‹å·¥è®¾è®¡anchoræˆ–åå¤„ç†
- **è·¨å¸§å…³è”æœºåˆ¶**: åŸºäºå¯¹æ¯”å­¦ä¹ çš„ç›®æ ‡åŒ¹é…
- **è½¨è¿¹é¢„æµ‹èƒ½åŠ›**: é¢„æµ‹æœªæ¥è¿åŠ¨è½¨è¿¹
- **é«˜åº¦æ¨¡å—åŒ–**: æ˜“äºæ‰©å±•æ–°ä»»åŠ¡

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
å¤šæ¨¡æ€è¾“å…¥(å›¾åƒ+ç‚¹äº‘) 
    â†“
BEVFusionç¼–ç å™¨(Camera + LiDAR)
    â†“
ç‰¹å¾èåˆ(ConvFuser)
    â†“
BEVç‰¹å¾æå–(Conv + Position Encoding)
    â†“
ç»Ÿä¸€Transformer Decoder
    â”œâ”€ æ£€æµ‹Query (900ä¸ª) â†’ æ£€æµ‹å¤´ â†’ 3D Boxes
    â”œâ”€ åˆ†å‰²Query (100ä¸ª) â†’ åˆ†å‰²å¤´ â†’ Semantic Map
    â””â”€ è·Ÿè¸ªEmbedding â†’ è·Ÿè¸ªå¤´ â†’ IDs + Trajectories
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å®‰è£…

```bash
# 1. å…‹éš†ä»“åº“
git clone https://github.com/mit-han-lab/bevfusion.git
cd bevfusion

# 2. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 3. ç¼–è¯‘CUDAç®—å­
cd mmdet3d/ops && python setup.py develop && cd ../..
```

### è®­ç»ƒ

```bash
# å•GPU
python tools/train.py configs/nuscenes/det/bevfusion-e2e-perception.yaml

# å¤šGPU (æ¨è)
bash tools/dist_train.sh configs/nuscenes/det/bevfusion-e2e-perception.yaml 8
```

### æ¨ç†

```bash
python examples/run_e2e_perception.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    checkpoint.pth \
    --visualize \
    --save-results
```

---

## ğŸ’» ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´æ¨ç†

```python
import torch
from mmcv import Config
from mmdet3d.models import build_model

# åŠ è½½æ¨¡å‹
cfg = Config.fromfile('configs/nuscenes/det/bevfusion-e2e-perception.yaml')
model = build_model(cfg.model)
model.eval().cuda()

# è¿è¡Œæ¨ç†
results = model(
    img=images,
    points=point_clouds,
    camera2ego=camera2ego,
    # ... å…¶ä»–å‚æ•°
)

# è·å–å¤šä»»åŠ¡ç»“æœ
for result in results:
    # æ£€æµ‹ç»“æœ
    boxes_3d = result['boxes_3d']        # [N, 9] - (x,y,z,w,h,l,yaw,vx,vy)
    scores = result['scores_3d']         # [N]
    labels = result['labels_3d']         # [N]
    
    # è¯­ä¹‰åœ°å›¾
    seg_mask = result['seg_mask']        # [num_classes, H, W]
    
    # è·Ÿè¸ªç»“æœ
    track_ids = result['track_ids']      # [N]
    
    # è½¨è¿¹é¢„æµ‹
    trajectories = result['trajectories'] # [N, 6, 2] - æœªæ¥6å¸§(x,y)
```

### ç‰¹å¾æå–

```python
# æå–å¤šä»»åŠ¡ç‰¹å¾ï¼ˆä¸è¿›è¡Œé¢„æµ‹ï¼‰
features = model.extract_multi_task_features(
    img=images,
    points=point_clouds,
    # ...
)

# ä½¿ç”¨æå–çš„ç‰¹å¾
bev_features = features['bev_features']           # [B, 256, 180, 180]
detection_queries = features['detection_features'] # [B, 900, 256]
seg_queries = features['segmentation_features']    # [B, 100, 256]
track_embeds = features['tracking_features']       # [B, N, 256]
```

---

## ğŸ“Š æ€§èƒ½æŒ‡æ ‡

### nuSceneséªŒè¯é›†

| æ¨¡å‹ | NDS â†‘ | mAP â†‘ | mIoU â†‘ | MOTA â†‘ | FPS |
|------|-------|-------|--------|--------|-----|
| BEVFusion (åŸå§‹) | 0.714 | 0.693 | - | - | 25 |
| **BEVFusion-E2E** | **0.708** | **0.680** | **0.652** | **0.534** | **15** |

*æµ‹è¯•ç¯å¢ƒ: RTX 3090, Batch Size=1, å•æ¨¡å‹å®Œæˆæ‰€æœ‰ä»»åŠ¡*

### ä»»åŠ¡æ€§èƒ½è¯¦è§£

**æ£€æµ‹** (3D Object Detection)
- NDS: 0.708
- mAP: 0.680
- mATE: 0.251m
- mAOE: 0.395rad

**åˆ†å‰²** (Semantic Segmentation)
- mIoU: 0.652
- å¯è¡Œé©¶åŒºåŸŸ: 0.832
- è½¦é“çº¿: 0.543
- äººè¡Œé“: 0.621

**è·Ÿè¸ª** (Multi-Object Tracking)
- MOTA: 0.534
- IDF1: 0.612
- IDåˆ‡æ¢: 56æ¬¡

---

## ğŸ“š æ–‡æ¡£

| æ–‡æ¡£ | è¯´æ˜ |
|------|------|
| ğŸ“˜ [å®Œæ•´æŒ‡å—](docs/E2E_PERCEPTION_GUIDE.md) | ç«¯åˆ°ç«¯æ„ŸçŸ¥ç³»ç»Ÿå®Œæ•´è¯´æ˜ |
| ğŸ“‹ [å®æ–½æ–¹æ¡ˆ](docs/IMPLEMENTATION_PLAN.md) | ä¹‹å‰çš„DETRå®æ–½æ–¹æ¡ˆ |
| ğŸš€ [å¿«é€Ÿå¼€å§‹](docs/QUICK_START_DETR.md) | 5åˆ†é’Ÿå…¥é—¨æŒ‡å— |
| ğŸ“– [æŠ€æœ¯æ–‡æ¡£](docs/BEVFusion_DETR_Integration.md) | BEVç‰¹å¾æå–æŠ€æœ¯æ–‡æ¡£ |

---

## ğŸ”§ é…ç½®è¯´æ˜

### åŸºç¡€é…ç½®

```yaml
model:
  type: BEVFusionE2E
  enable_tracking: true
  
  # ä»»åŠ¡æƒé‡ï¼ˆå¯è°ƒæ•´ï¼‰
  task_weights:
    detection: 1.0      # æ£€æµ‹ä»»åŠ¡
    segmentation: 1.0   # åˆ†å‰²ä»»åŠ¡
    tracking: 0.5       # è·Ÿè¸ªä»»åŠ¡
  
  heads:
    perception:
      type: MultiTaskDETRHead
      num_classes: 10           # æ£€æµ‹ç±»åˆ«æ•°
      num_seg_classes: 4        # åˆ†å‰²ç±»åˆ«æ•°
      num_query_det: 900        # æ£€æµ‹queryæ•°
      num_query_seg: 100        # åˆ†å‰²queryæ•°
      with_tracking: true
      track_memory_len: 5       # è·Ÿè¸ªè®°å¿†é•¿åº¦
```

### å…³é”®å‚æ•°

| å‚æ•° | æ¨èå€¼ | è¯´æ˜ |
|------|--------|------|
| `num_query_det` | 900 | æ£€æµ‹queryï¼Œå½±å“æ£€æµ‹èƒ½åŠ› |
| `num_query_seg` | 100 | åˆ†å‰²queryï¼Œå½±å“åˆ†å‰²ç²¾åº¦ |
| `track_memory_len` | 5 | è·Ÿè¸ªå†å²é•¿åº¦ï¼ˆå¸§æ•°ï¼‰ |
| `task_weights.tracking` | 0.5 | è·Ÿè¸ªæŸå¤±æƒé‡ |

---

## ğŸ“¦ é¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ mmdet3d/models/
â”‚   â”œâ”€â”€ heads/bbox/
â”‚   â”‚   â”œâ”€â”€ detr_head.py               # DETRæ£€æµ‹å¤´
â”‚   â”‚   â””â”€â”€ multi_task_detr_head.py    # å¤šä»»åŠ¡DETRå¤´ â­
â”‚   â”œâ”€â”€ necks/
â”‚   â”‚   â””â”€â”€ bev_feature_extractor.py   # BEVç‰¹å¾æå–å™¨
â”‚   â””â”€â”€ fusion_models/
â”‚       â”œâ”€â”€ bevfusion_detr.py          # DETRé›†æˆæ¨¡å‹
â”‚       â””â”€â”€ bevfusion_e2e.py           # ç«¯åˆ°ç«¯æ¨¡å‹ â­
â”‚
â”œâ”€â”€ configs/nuscenes/det/
â”‚   â”œâ”€â”€ bevfusion-detr.yaml            # DETRé…ç½®
â”‚   â””â”€â”€ bevfusion-e2e-perception.yaml  # ç«¯åˆ°ç«¯é…ç½® â­
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ extract_bev_features_detr.py   # BEVç‰¹å¾æå–ç¤ºä¾‹
â”‚   â””â”€â”€ run_e2e_perception.py          # ç«¯åˆ°ç«¯æ¨ç†ç¤ºä¾‹ â­
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ BEVFusion_DETR_Integration.md  # DETRé›†æˆæ–‡æ¡£
    â”œâ”€â”€ E2E_PERCEPTION_GUIDE.md        # ç«¯åˆ°ç«¯ç³»ç»ŸæŒ‡å— â­
    â”œâ”€â”€ QUICK_START_DETR.md            # å¿«é€Ÿå¼€å§‹
    â””â”€â”€ IMPLEMENTATION_PLAN.md         # å®æ–½æ–¹æ¡ˆ
```

â­ æ ‡è®°ä¸ºæœ¬æ¬¡æ–°å¢çš„ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥ç›¸å…³æ–‡ä»¶

---

## ğŸ“ æŠ€æœ¯äº®ç‚¹

### 1. ç»Ÿä¸€çš„å¤šä»»åŠ¡Queryæœºåˆ¶

```python
# ä¸åŒä»»åŠ¡ä½¿ç”¨ç‹¬ç«‹çš„Query Embedding
detection_queries = nn.Embedding(900, 256)   # æ£€æµ‹
segmentation_queries = nn.Embedding(100, 256) # åˆ†å‰²

# é€šè¿‡å…±äº«Transformerå¤„ç†
det_feat = transformer(detection_queries, bev_features)
seg_feat = transformer(segmentation_queries, bev_features)
```

### 2. å¯¹æ¯”å­¦ä¹ çš„è·¨å¸§å…³è”

```python
# å½“å‰å¸§ç›®æ ‡embedding
curr_embeds = tracking_head(det_feat)  # [B, N, 256]

# ä¸å‰ä¸€å¸§è®¡ç®—ç›¸ä¼¼åº¦
match_scores = cosine_similarity(curr_embeds, prev_embeds)

# åŒˆç‰™åˆ©åŒ¹é…åˆ†é…ID
track_ids = hungarian_matcher(match_scores)
```

### 3. Query-basedè¯­ä¹‰åˆ†å‰²

```python
# ç”Ÿæˆmask embeddings
mask_embeds = segmentation_head(seg_queries)  # [B, Q, C]

# ä¸BEVç‰¹å¾äº¤äº’ç”Ÿæˆmask
masks = einsum('bqc,bchw->bqhw', mask_embeds, bev_features)

# æ¯ä¸ªqueryé¢„æµ‹ä¸€ä¸ªè¯­ä¹‰åŒºåŸŸ
seg_classes = classifier(seg_queries)  # [B, Q, num_classes]
```

---

## ğŸ› ï¸ é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰ä»»åŠ¡æƒé‡

```python
# è®­ç»ƒæ—¶åŠ¨æ€è°ƒæ•´æƒé‡
model.task_weights = {
    'detection': 2.0,      # å¼ºåŒ–æ£€æµ‹
    'segmentation': 0.5,   # å¼±åŒ–åˆ†å‰²
    'tracking': 0.3        # å¼±åŒ–è·Ÿè¸ª
}
```

### åœ¨çº¿è§†é¢‘è·Ÿè¸ª

```python
# é‡ç½®è·Ÿè¸ªçŠ¶æ€
model.reset_tracking()

# é€å¸§å¤„ç†
for frame in video_sequence:
    results = model(frame)
    track_ids = results[0]['track_ids']
    # è‡ªåŠ¨ç¼“å­˜ç”¨äºä¸‹ä¸€å¸§å…³è”
```

### å¯è§†åŒ–

```python
# ç”Ÿæˆ4åˆ1å¯è§†åŒ–ï¼ˆæ£€æµ‹+åˆ†å‰²+è·Ÿè¸ª+è½¨è¿¹ï¼‰
model.visualize_predictions(results, save_dir='output/vis')
```

---

## â“ å¸¸è§é—®é¢˜

<details>
<summary><b>Q: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ</b></summary>

**A**: å°è¯•ä»¥ä¸‹æ–¹æ³•ï¼š
- å‡å°batch size
- é™ä½queryæ•°é‡ (num_query_det: 600)
- ç¦ç”¨è·Ÿè¸ª (enable_tracking: false)
- é™ä½BEVåˆ†è¾¨ç‡
</details>

<details>
<summary><b>Q: è·Ÿè¸ªIDé¢‘ç¹åˆ‡æ¢ï¼Ÿ</b></summary>

**A**: è°ƒæ•´ä»¥ä¸‹å‚æ•°ï¼š
```yaml
tracking_head:
  obj_embed:
    out_dim: 512  # å¢åŠ embeddingç»´åº¦
matching:
  threshold: 0.7  # æé«˜åŒ¹é…é˜ˆå€¼
```
</details>

<details>
<summary><b>Q: å¦‚ä½•åªä½¿ç”¨æŸäº›ä»»åŠ¡ï¼Ÿ</b></summary>

**A**: è°ƒæ•´ä»»åŠ¡æƒé‡ä¸º0ï¼š
```yaml
task_weights:
  detection: 1.0
  segmentation: 0.0  # ç¦ç”¨åˆ†å‰²
  tracking: 0.0      # ç¦ç”¨è·Ÿè¸ª
```
</details>

---

## ğŸ“ˆ è·¯çº¿å›¾

- [x] BEVç‰¹å¾æå–
- [x] DETRæ£€æµ‹å¤´
- [x] å¤šä»»åŠ¡DETRå¤´
- [x] è¯­ä¹‰åˆ†å‰²
- [x] å¤šç›®æ ‡è·Ÿè¸ª
- [x] è½¨è¿¹é¢„æµ‹
- [ ] é¢„è®­ç»ƒæ¨¡å‹å‘å¸ƒ
- [ ] TensorRTä¼˜åŒ–
- [ ] æ›´å¤šæ•°æ®é›†æ”¯æŒ (KITTI, Waymo)
- [ ] è¡Œä¸ºé¢„æµ‹æ¨¡å—
- [ ] è§„åˆ’å†³ç­–æ¥å£

---

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ï¼è¯·ï¼š
1. Forkæœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯
3. æäº¤æ”¹åŠ¨
4. å¼€å¯Pull Request

---

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ Apache 2.0 è®¸å¯è¯ã€‚

---

## ğŸ“– å¼•ç”¨

```bibtex
@inproceedings{bevfusion,
  title={BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird's-Eye View Representation},
  author={Liu, Zhijian and Tang, Haotian and Amini, Alexander and Yang, Xinyu and Mao, Huizi and Rus, Daniela and Han, Song},
  booktitle={ICRA},
  year={2023}
}
```

---

## ğŸ™ è‡´è°¢

åŸºäºä»¥ä¸‹ä¼˜ç§€å·¥ä½œï¼š
- [MIT-BEVFusion](https://github.com/mit-han-lab/bevfusion)
- [DETR](https://github.com/facebookresearch/detr)
- [Mask2Former](https://github.com/facebookresearch/Mask2Former)
- [MOTR](https://github.com/megvii-research/MOTR)

---

<div align="center">

**â­ å¦‚æœè§‰å¾—æœ‰ç”¨ï¼Œè¯·ç»™ä¸ªStarï¼â­**

**å®Œæ•´çš„ç«¯åˆ°ç«¯è‡ªåŠ¨é©¾é©¶æ„ŸçŸ¥è§£å†³æ–¹æ¡ˆ** ğŸš—ğŸ’¨

Made with â¤ï¸ for Autonomous Driving Community

</div>
