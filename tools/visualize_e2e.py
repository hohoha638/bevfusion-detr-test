"""
BEVFusion ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥å¯è§†åŒ–å·¥å…·

åŠŸèƒ½:
- 3Dæ£€æµ‹æ¡†å¯è§†åŒ–ï¼ˆBEVè§†å›¾å’Œé€è§†å›¾ï¼‰
- è¯­ä¹‰åœ°å›¾å¯è§†åŒ–
- å¤šç›®æ ‡è·Ÿè¸ªå¯è§†åŒ–
- è½¨è¿¹é¢„æµ‹å¯è§†åŒ–
- ç”Ÿæˆè§†é¢‘å’ŒGIF
"""

import os
import cv2
import numpy as np
import torch
import matplotlib
matplotlib.use('Agg')  # æ— å¤´æ¨¡å¼
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, Polygon
from matplotlib.collections import PatchCollection
import argparse
from pathlib import Path
from tqdm import tqdm
import imageio
from PIL import Image, ImageDraw, ImageFont

# é¢œè‰²æ–¹æ¡ˆ
COLORS = {
    'car': (255, 158, 0),
    'truck': (255, 99, 71),
    'bus': (255, 140, 0),
    'trailer': (255, 127, 80),
    'construction_vehicle': (233, 150, 70),
    'pedestrian': (0, 0, 230),
    'motorcycle': (255, 61, 99),
    'bicycle': (220, 20, 60),
    'traffic_cone': (255, 255, 0),
    'barrier': (112, 128, 144),
}

SEGMENTATION_COLORS = {
    0: (128, 64, 128),   # Drivable area (ç´«è‰²)
    1: (244, 35, 232),   # Lane (å“çº¢)
    2: (70, 70, 70),     # Sidewalk (ç°è‰²)
    3: (102, 102, 156),  # Other (è“ç°)
}

CLASS_NAMES = [
    'car', 'truck', 'bus', 'trailer', 'construction_vehicle',
    'pedestrian', 'motorcycle', 'bicycle', 'traffic_cone', 'barrier'
]


class E2EVisualizer:
    """ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥å¯è§†åŒ–å™¨"""
    
    def __init__(self, output_dir='output/visualization', dpi=150, figsize=(20, 15)):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.dpi = dpi
        self.figsize = figsize
        
        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / 'detection').mkdir(exist_ok=True)
        (self.output_dir / 'segmentation').mkdir(exist_ok=True)
        (self.output_dir / 'tracking').mkdir(exist_ok=True)
        (self.output_dir / 'combined').mkdir(exist_ok=True)
    
    def visualize_sample(self, result, img=None, frame_id=0, save=True):
        """
        å¯è§†åŒ–å•ä¸ªæ ·æœ¬çš„æ‰€æœ‰ä»»åŠ¡
        
        Args:
            result: æ¨¡å‹è¾“å‡ºç»“æœå­—å…¸
            img: åŸå§‹å›¾åƒï¼ˆå¯é€‰ï¼‰
            frame_id: å¸§ID
            save: æ˜¯å¦ä¿å­˜
        """
        fig, axes = plt.subplots(2, 2, figsize=self.figsize)
        
        # 1. 3Dæ£€æµ‹å¯è§†åŒ– (å·¦ä¸Š)
        self._plot_detection_bev(axes[0, 0], result)
        axes[0, 0].set_title('3D Object Detection (BEV View)', fontsize=14, fontweight='bold')
        
        # 2. è¯­ä¹‰åœ°å›¾å¯è§†åŒ– (å³ä¸Š)
        self._plot_segmentation(axes[0, 1], result)
        axes[0, 1].set_title('Semantic Map', fontsize=14, fontweight='bold')
        
        # 3. å¤šç›®æ ‡è·Ÿè¸ªå¯è§†åŒ– (å·¦ä¸‹)
        self._plot_tracking(axes[1, 0], result)
        axes[1, 0].set_title('Multi-Object Tracking', fontsize=14, fontweight='bold')
        
        # 4. è½¨è¿¹é¢„æµ‹å¯è§†åŒ– (å³ä¸‹)
        self._plot_trajectories(axes[1, 1], result)
        axes[1, 1].set_title('Trajectory Prediction', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        
        if save:
            save_path = self.output_dir / 'combined' / f'frame_{frame_id:04d}.png'
            plt.savefig(save_path, dpi=self.dpi, bbox_inches='tight')
            print(f"âœ“ Saved: {save_path}")
        
        plt.close()
        
        return fig
    
    def _plot_detection_bev(self, ax, result):
        """ç»˜åˆ¶BEVæ£€æµ‹ç»“æœ"""
        boxes = result.get('boxes_3d', None)
        scores = result.get('scores_3d', None)
        labels = result.get('labels_3d', None)
        
        if boxes is None or len(boxes) == 0:
            ax.text(0.5, 0.5, 'No detections', ha='center', va='center', fontsize=20)
            ax.set_xlim(-50, 50)
            ax.set_ylim(-50, 50)
            return
        
        # è½¬æ¢ä¸ºnumpy
        boxes = boxes.cpu().numpy() if torch.is_tensor(boxes) else boxes
        scores = scores.cpu().numpy() if torch.is_tensor(scores) else scores
        labels = labels.cpu().numpy() if torch.is_tensor(labels) else labels
        
        # ç»˜åˆ¶è‡ªè½¦
        ego_rect = Rectangle((-2, -1), 4, 2, linewidth=3, edgecolor='blue', facecolor='lightblue', alpha=0.5)
        ax.add_patch(ego_rect)
        ax.text(0, 0, 'EGO', ha='center', va='center', fontsize=10, fontweight='bold')
        
        # ç»˜åˆ¶æ£€æµ‹æ¡†
        for box, score, label in zip(boxes, scores, labels):
            if score < 0.3:  # è¿‡æ»¤ä½ç½®ä¿¡åº¦
                continue
            
            x, y, z, w, h, l, yaw = box[0], box[1], box[2], box[3], box[4], box[5], box[6]
            
            # è·å–é¢œè‰²
            class_name = CLASS_NAMES[int(label)] if int(label) < len(CLASS_NAMES) else 'unknown'
            color = np.array(COLORS.get(class_name, (128, 128, 128))) / 255.0
            
            # è®¡ç®—å››ä¸ªè§’ç‚¹
            corners = self._get_box_corners(x, y, w, l, yaw)
            
            # ç»˜åˆ¶æ¡†
            poly = Polygon(corners, closed=True, linewidth=2, 
                          edgecolor=color, facecolor=color, alpha=0.3)
            ax.add_patch(poly)
            
            # ç»˜åˆ¶æœå‘ç®­å¤´
            arrow_length = l / 2
            dx = arrow_length * np.cos(yaw)
            dy = arrow_length * np.sin(yaw)
            ax.arrow(x, y, dx, dy, head_width=1.0, head_length=0.5, 
                    fc=color, ec=color, linewidth=2)
            
            # æ ‡æ³¨ç±»åˆ«å’Œç½®ä¿¡åº¦
            ax.text(x, y + h/2 + 1, f'{class_name}\n{score:.2f}', 
                   ha='center', va='bottom', fontsize=8,
                   bbox=dict(boxstyle='round,pad=0.3', facecolor=color, alpha=0.7),
                   color='white', fontweight='bold')
        
        # è®¾ç½®åæ ‡è½´
        ax.set_xlim(-50, 50)
        ax.set_ylim(-50, 50)
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3)
        ax.set_xlabel('X (m)', fontsize=12)
        ax.set_ylabel('Y (m)', fontsize=12)
        
        # æ·»åŠ å›¾ä¾‹
        legend_elements = [
            plt.Line2D([0], [0], marker='s', color='w', 
                      markerfacecolor=np.array(COLORS[name])/255.0, 
                      markersize=10, label=name.capitalize())
            for name in ['car', 'pedestrian', 'truck', 'bicycle']
        ]
        ax.legend(handles=legend_elements, loc='upper right', fontsize=8)
    
    def _plot_segmentation(self, ax, result):
        """ç»˜åˆ¶è¯­ä¹‰åˆ†å‰²åœ°å›¾"""
        seg_mask = result.get('seg_mask', None)
        
        if seg_mask is None:
            ax.text(0.5, 0.5, 'No segmentation', ha='center', va='center', fontsize=20)
            return
        
        # è½¬æ¢ä¸ºnumpy
        if torch.is_tensor(seg_mask):
            seg_mask = seg_mask.cpu().numpy()
        
        # åˆ›å»ºRGBå›¾åƒ
        num_classes, H, W = seg_mask.shape
        rgb_mask = np.zeros((H, W, 3), dtype=np.uint8)
        
        # åº”ç”¨é¢œè‰²
        for cls_id in range(num_classes):
            mask = seg_mask[cls_id] > 0.5
            color = SEGMENTATION_COLORS.get(cls_id, (128, 128, 128))
            rgb_mask[mask] = color
        
        # æ˜¾ç¤º
        ax.imshow(rgb_mask, origin='lower')
        ax.axis('off')
        
        # æ·»åŠ å›¾ä¾‹
        from matplotlib.patches import Patch
        legend_labels = ['Drivable', 'Lane', 'Sidewalk', 'Other']
        legend_elements = [
            Patch(facecolor=np.array(SEGMENTATION_COLORS[i])/255.0, label=legend_labels[i])
            for i in range(min(num_classes, len(legend_labels)))
        ]
        ax.legend(handles=legend_elements, loc='upper right', fontsize=10)
    
    def _plot_tracking(self, ax, result):
        """ç»˜åˆ¶è·Ÿè¸ªç»“æœ"""
        boxes = result.get('boxes_3d', None)
        track_ids = result.get('track_ids', None)
        
        if boxes is None or track_ids is None or len(boxes) == 0:
            ax.text(0.5, 0.5, 'No tracking', ha='center', va='center', fontsize=20)
            ax.set_xlim(-50, 50)
            ax.set_ylim(-50, 50)
            return
        
        # è½¬æ¢ä¸ºnumpy
        boxes = boxes.cpu().numpy() if torch.is_tensor(boxes) else boxes
        track_ids = track_ids.cpu().numpy() if torch.is_tensor(track_ids) else track_ids
        
        # ç»˜åˆ¶è‡ªè½¦
        ego_rect = Rectangle((-2, -1), 4, 2, linewidth=3, edgecolor='blue', facecolor='lightblue', alpha=0.5)
        ax.add_patch(ego_rect)
        
        # ä¸ºæ¯ä¸ªtrack IDåˆ†é…é¢œè‰²
        unique_ids = np.unique(track_ids)
        cmap = plt.cm.get_cmap('tab20')
        id_colors = {uid: cmap(i % 20) for i, uid in enumerate(unique_ids)}
        
        # ç»˜åˆ¶è·Ÿè¸ªæ¡†
        for box, tid in zip(boxes, track_ids):
            x, y, w, l, yaw = box[0], box[1], box[3], box[5], box[6]
            
            color = id_colors[tid]
            corners = self._get_box_corners(x, y, w, l, yaw)
            
            # ç»˜åˆ¶æ¡†
            poly = Polygon(corners, closed=True, linewidth=3,
                          edgecolor=color, facecolor='none')
            ax.add_patch(poly)
            
            # ç»˜åˆ¶ID
            ax.text(x, y, f'ID:{tid}', ha='center', va='center',
                   fontsize=12, fontweight='bold',
                   bbox=dict(boxstyle='round,pad=0.4', facecolor=color, alpha=0.8),
                   color='white')
        
        ax.set_xlim(-50, 50)
        ax.set_ylim(-50, 50)
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3)
        ax.set_xlabel('X (m)', fontsize=12)
        ax.set_ylabel('Y (m)', fontsize=12)
    
    def _plot_trajectories(self, ax, result):
        """ç»˜åˆ¶è½¨è¿¹é¢„æµ‹"""
        boxes = result.get('boxes_3d', None)
        trajs = result.get('trajectories', None)
        labels = result.get('labels_3d', None)
        
        if boxes is None or trajs is None or len(boxes) == 0:
            ax.text(0.5, 0.5, 'No trajectories', ha='center', va='center', fontsize=20)
            ax.set_xlim(-50, 50)
            ax.set_ylim(-50, 50)
            return
        
        # è½¬æ¢ä¸ºnumpy
        boxes = boxes.cpu().numpy() if torch.is_tensor(boxes) else boxes
        trajs = trajs.cpu().numpy() if torch.is_tensor(trajs) else trajs
        labels = labels.cpu().numpy() if torch.is_tensor(labels) else labels
        
        # ç»˜åˆ¶è‡ªè½¦
        ego_rect = Rectangle((-2, -1), 4, 2, linewidth=3, edgecolor='blue', facecolor='lightblue', alpha=0.5)
        ax.add_patch(ego_rect)
        
        # ç»˜åˆ¶å½“å‰ä½ç½®å’Œè½¨è¿¹
        for box, traj, label in zip(boxes, trajs, labels):
            x, y = box[0], box[1]
            
            # è·å–é¢œè‰²
            class_name = CLASS_NAMES[int(label)] if int(label) < len(CLASS_NAMES) else 'unknown'
            color = np.array(COLORS.get(class_name, (128, 128, 128))) / 255.0
            
            # å½“å‰ä½ç½®
            ax.plot(x, y, 'o', color=color, markersize=12, markeredgecolor='white', markeredgewidth=2)
            
            # è½¨è¿¹ç‚¹ï¼ˆç›¸å¯¹åæ ‡ï¼‰
            traj_x = traj[:, 0] + x
            traj_y = traj[:, 1] + y
            
            # ç»˜åˆ¶è½¨è¿¹çº¿
            ax.plot(traj_x, traj_y, '--', color=color, linewidth=2, alpha=0.7)
            
            # ç»˜åˆ¶è½¨è¿¹ç‚¹
            ax.plot(traj_x, traj_y, 'o', color=color, markersize=6, alpha=0.7)
            
            # æ ‡æ³¨æ—¶é—´æ­¥
            for t, (tx, ty) in enumerate(zip(traj_x, traj_y)):
                ax.text(tx, ty, f't+{t+1}', fontsize=7, ha='center', va='bottom',
                       color='black', bbox=dict(boxstyle='round,pad=0.2', 
                       facecolor='white', alpha=0.7))
        
        ax.set_xlim(-50, 50)
        ax.set_ylim(-50, 50)
        ax.set_aspect('equal')
        ax.grid(True, alpha=0.3)
        ax.set_xlabel('X (m)', fontsize=12)
        ax.set_ylabel('Y (m)', fontsize=12)
    
    def _get_box_corners(self, x, y, w, l, yaw):
        """è®¡ç®—boxçš„å››ä¸ªè§’ç‚¹"""
        # ä¸­å¿ƒç‚¹
        cx, cy = x, y
        
        # æœªæ—‹è½¬çš„è§’ç‚¹ï¼ˆç›¸å¯¹äºä¸­å¿ƒï¼‰
        corners_local = np.array([
            [-l/2, -w/2],
            [l/2, -w/2],
            [l/2, w/2],
            [-l/2, w/2]
        ])
        
        # æ—‹è½¬çŸ©é˜µ
        cos_yaw = np.cos(yaw)
        sin_yaw = np.sin(yaw)
        rot_matrix = np.array([
            [cos_yaw, -sin_yaw],
            [sin_yaw, cos_yaw]
        ])
        
        # æ—‹è½¬å¹¶å¹³ç§»
        corners = corners_local @ rot_matrix.T
        corners[:, 0] += cx
        corners[:, 1] += cy
        
        return corners
    
    def create_video(self, results, output_path='output/perception_video.mp4', 
                     fps=10, imgs=None):
        """
        åˆ›å»ºå¯è§†åŒ–è§†é¢‘
        
        Args:
            results: ç»“æœåˆ—è¡¨
            output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
            fps: å¸§ç‡
            imgs: åŸå§‹å›¾åƒåˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        """
        print(f"\nğŸ¬ åˆ›å»ºè§†é¢‘: {output_path}")
        
        # ç”Ÿæˆå¸§
        frames = []
        for i, result in enumerate(tqdm(results, desc="æ¸²æŸ“å¸§")):
            # ç”Ÿæˆå¯è§†åŒ–
            fig = self.visualize_sample(result, 
                                       img=imgs[i] if imgs else None,
                                       frame_id=i, 
                                       save=False)
            
            # è½¬æ¢ä¸ºå›¾åƒ
            fig.canvas.draw()
            frame = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)
            frame = frame.reshape(fig.canvas.get_width_height()[::-1] + (3,))
            frames.append(frame)
            plt.close(fig)
        
        # å†™å…¥è§†é¢‘
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        imageio.mimsave(str(output_path), frames, fps=fps)
        print(f"âœ“ è§†é¢‘å·²ä¿å­˜: {output_path}")
        
        # åŒæ—¶ä¿å­˜GIFï¼ˆå‰30å¸§ï¼‰
        gif_path = output_path.with_suffix('.gif')
        imageio.mimsave(str(gif_path), frames[:min(30, len(frames))], fps=fps//2)
        print(f"âœ“ GIFå·²ä¿å­˜: {gif_path}")
    
    def create_comparison_grid(self, results_list, labels, output_path='output/comparison.png'):
        """
        åˆ›å»ºå¯¹æ¯”ç½‘æ ¼å›¾
        
        Args:
            results_list: å¤šä¸ªæ¨¡å‹çš„ç»“æœåˆ—è¡¨
            labels: æ¨¡å‹æ ‡ç­¾
            output_path: è¾“å‡ºè·¯å¾„
        """
        n_models = len(results_list)
        fig, axes = plt.subplots(n_models, 4, figsize=(20, 5*n_models))
        
        if n_models == 1:
            axes = axes.reshape(1, -1)
        
        for i, (results, label) in enumerate(zip(results_list, labels)):
            result = results[0]  # å–ç¬¬ä¸€ä¸ªæ ·æœ¬
            
            # ç»˜åˆ¶å››ä¸ªä»»åŠ¡
            self._plot_detection_bev(axes[i, 0], result)
            self._plot_segmentation(axes[i, 1], result)
            self._plot_tracking(axes[i, 2], result)
            self._plot_trajectories(axes[i, 3], result)
            
            # æ·»åŠ æ¨¡å‹æ ‡ç­¾
            axes[i, 0].set_ylabel(label, fontsize=14, fontweight='bold')
        
        # æ·»åŠ åˆ—æ ‡é¢˜
        axes[0, 0].set_title('Detection', fontsize=14, fontweight='bold')
        axes[0, 1].set_title('Segmentation', fontsize=14, fontweight='bold')
        axes[0, 2].set_title('Tracking', fontsize=14, fontweight='bold')
        axes[0, 3].set_title('Trajectories', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(output_path, dpi=self.dpi, bbox_inches='tight')
        plt.close()
        
        print(f"âœ“ å¯¹æ¯”å›¾å·²ä¿å­˜: {output_path}")


def main():
    parser = argparse.ArgumentParser(description='BEVFusion E2E å¯è§†åŒ–å·¥å…·')
    parser.add_argument('--results', type=str, required=True, help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆ.npzï¼‰')
    parser.add_argument('--output', type=str, default='output/visualization', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--video', action='store_true', help='ç”Ÿæˆè§†é¢‘')
    parser.add_argument('--fps', type=int, default=10, help='è§†é¢‘å¸§ç‡')
    parser.add_argument('--num-samples', type=int, default=-1, help='å¯è§†åŒ–æ ·æœ¬æ•°ï¼ˆ-1è¡¨ç¤ºå…¨éƒ¨ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½ç»“æœ
    print(f"ğŸ“‚ åŠ è½½ç»“æœ: {args.results}")
    
    if args.results.endswith('.npz'):
        # å•ä¸ªæ–‡ä»¶
        data = np.load(args.results, allow_pickle=True)
        results = [data]
    else:
        # ç›®å½•
        result_files = sorted(Path(args.results).glob('*.npz'))
        results = [np.load(f, allow_pickle=True) for f in result_files]
    
    if args.num_samples > 0:
        results = results[:args.num_samples]
    
    print(f"âœ“ åŠ è½½äº† {len(results)} ä¸ªç»“æœ")
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = E2EVisualizer(output_dir=args.output)
    
    # å¯è§†åŒ–æ¯ä¸ªæ ·æœ¬
    print("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–...")
    for i, result_data in enumerate(tqdm(results)):
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        result = {key: result_data[key] for key in result_data.files}
        
        # å¯è§†åŒ–
        visualizer.visualize_sample(result, frame_id=i, save=True)
    
    # ç”Ÿæˆè§†é¢‘
    if args.video and len(results) > 1:
        results_list = [{key: r[key] for key in r.files} for r in results]
        visualizer.create_video(results_list, 
                               output_path=f'{args.output}/perception_video.mp4',
                               fps=args.fps)
    
    print("\nâœ… å¯è§†åŒ–å®Œæˆï¼")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {args.output}")


if __name__ == '__main__':
    main()
