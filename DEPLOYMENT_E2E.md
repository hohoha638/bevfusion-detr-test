# BEVFusion ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥ç³»ç»Ÿ - å®Œæ•´éƒ¨ç½²æ–¹æ¡ˆ

## ğŸ“‹ ç›®å½•

- [éƒ¨ç½²æ¶æ„](#éƒ¨ç½²æ¶æ„)
- [æ€§èƒ½ä¼˜åŒ–](#æ€§èƒ½ä¼˜åŒ–)
- [ç”Ÿäº§éƒ¨ç½²](#ç”Ÿäº§éƒ¨ç½²)
- [æ¨ç†æœåŠ¡](#æ¨ç†æœåŠ¡)
- [ç›‘æ§ä¸ç»´æŠ¤](#ç›‘æ§ä¸ç»´æŠ¤)

---

## ğŸ—ï¸ éƒ¨ç½²æ¶æ„

### æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ•°æ®é‡‡é›†å±‚                                  â”‚
â”‚              æ‘„åƒå¤´Ã—6 + LiDAR + é¢„å¤„ç†                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ¨ç†å¼•æ“å±‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ TensorRTä¼˜åŒ– â”‚  â”‚  æ¨¡å‹æ¨ç†     â”‚  â”‚  ç»“æœåå¤„ç†   â”‚      â”‚
â”‚  â”‚  æ¨¡å‹åŠ é€Ÿ    â”‚  â”‚  å¤šä»»åŠ¡è¾“å‡º   â”‚  â”‚  NMS/è¿½è¸ª    â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åº”ç”¨æœåŠ¡å±‚                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ å¯è§†åŒ–æœåŠ¡   â”‚  â”‚  APIæœåŠ¡      â”‚  â”‚  å­˜å‚¨æœåŠ¡     â”‚      â”‚
â”‚  â”‚ Web/ROS     â”‚  â”‚  REST/gRPC   â”‚  â”‚  æ•°æ®åº“/æ–‡ä»¶  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### éƒ¨ç½²æ¨¡å¼

#### 1. å•æœºéƒ¨ç½²ï¼ˆå¼€å‘/æµ‹è¯•ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   å·¥ä½œç«™/æœåŠ¡å™¨     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ GPU Ã— 1-2    â”‚  â”‚
â”‚  â”‚ æ¨¡å‹æ¨ç†     â”‚  â”‚
â”‚  â”‚ å¯è§†åŒ–       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 2. è½¦è½½éƒ¨ç½²ï¼ˆè¾¹ç¼˜è®¡ç®—ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   è½¦è½½è®¡ç®—å•å…ƒ      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ NVIDIA AGX   â”‚  â”‚
â”‚  â”‚ Xavier/Orin  â”‚  â”‚
â”‚  â”‚ TensorRTä¼˜åŒ– â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. äº‘ç«¯éƒ¨ç½²ï¼ˆæ‰¹é‡å¤„ç†ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ¨ç†èŠ‚ç‚¹ #1  â”‚  â”‚ æ¨ç†èŠ‚ç‚¹ #2  â”‚  â”‚ æ¨ç†èŠ‚ç‚¹ #N  â”‚
â”‚  GPU Ã— 8     â”‚  â”‚  GPU Ã— 8     â”‚  â”‚  GPU Ã— 8     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚                 â”‚                 â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  è´Ÿè½½å‡è¡¡å™¨      â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. æ¨¡å‹ä¼˜åŒ–

#### TensorRT åŠ é€Ÿ

```bash
# å¯¼å‡ºONNXæ¨¡å‹
python tools/deployment/export_onnx.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --output-file deploy/model.onnx \
    --shape 1,6,3,256,704

# è½¬æ¢ä¸ºTensorRTå¼•æ“
trtexec \
    --onnx=deploy/model.onnx \
    --saveEngine=deploy/model.trt \
    --fp16 \
    --workspace=8192 \
    --minShapes=input:1x6x3x256x704 \
    --optShapes=input:1x6x3x256x704 \
    --maxShapes=input:1x6x3x256x704 \
    --verbose
```

#### é‡åŒ–åŠ é€Ÿ

```python
# åŠ¨æ€é‡åŒ–
import torch
from torch.quantization import quantize_dynamic

model = build_model(cfg.model).eval()
model_quantized = quantize_dynamic(
    model,
    {torch.nn.Linear, torch.nn.Conv2d},
    dtype=torch.qint8
)

# ä¿å­˜é‡åŒ–æ¨¡å‹
torch.save(model_quantized.state_dict(), 'deploy/model_int8.pth')
```

#### æ··åˆç²¾åº¦æ¨ç†

```python
# ä½¿ç”¨AMPåŠ é€Ÿ
from torch.cuda.amp import autocast

model.eval().cuda()
with torch.no_grad():
    with autocast():
        results = model(**data)
```

### 2. æ•°æ®ä¼˜åŒ–

#### é¢„å¤„ç†ä¼˜åŒ–

```python
# ä½¿ç”¨DALIåŠ é€Ÿæ•°æ®åŠ è½½
from nvidia.dali import pipeline_def
import nvidia.dali.fn as fn
import nvidia.dali.types as types

@pipeline_def
def preprocess_pipeline():
    images = fn.readers.file(file_root="data/images")
    images = fn.decoders.image(images, device="mixed")
    images = fn.resize(images, resize_x=704, resize_y=256)
    images = fn.normalize(images, mean=[0.485, 0.456, 0.406], stddev=[0.229, 0.224, 0.225])
    return images
```

#### æ‰¹å¤„ç†ä¼˜åŒ–

```python
# åŠ¨æ€æ‰¹å¤„ç†
class DynamicBatcher:
    def __init__(self, max_batch_size=4, max_wait_time=0.1):
        self.max_batch_size = max_batch_size
        self.max_wait_time = max_wait_time
        self.buffer = []
    
    def add_sample(self, sample):
        self.buffer.append(sample)
        if len(self.buffer) >= self.max_batch_size:
            return self.flush()
        return None
    
    def flush(self):
        if not self.buffer:
            return None
        batch = collate_fn(self.buffer)
        self.buffer = []
        return batch
```

### 3. æ¨ç†ä¼˜åŒ–

#### Pipelineå¹¶è¡Œ

```python
import threading
from queue import Queue

class PipelineInference:
    def __init__(self, model, num_threads=3):
        self.model = model
        self.preprocess_queue = Queue(maxsize=10)
        self.inference_queue = Queue(maxsize=10)
        self.postprocess_queue = Queue(maxsize=10)
        
        # å¯åŠ¨pipeline
        threading.Thread(target=self._preprocess_worker).start()
        threading.Thread(target=self._inference_worker).start()
        threading.Thread(target=self._postprocess_worker).start()
    
    def _preprocess_worker(self):
        while True:
            raw_data = self.preprocess_queue.get()
            processed = preprocess(raw_data)
            self.inference_queue.put(processed)
    
    def _inference_worker(self):
        while True:
            data = self.inference_queue.get()
            results = self.model(**data)
            self.postprocess_queue.put(results)
    
    def _postprocess_worker(self):
        while True:
            results = self.postprocess_queue.get()
            final = postprocess(results)
            yield final
```

---

## ğŸš€ ç”Ÿäº§éƒ¨ç½²

### æ–¹æ¡ˆ 1: Docker å®¹å™¨åŒ–éƒ¨ç½²

#### Dockerfile

```dockerfile
FROM nvcr.io/nvidia/pytorch:21.12-py3

WORKDIR /app

# å®‰è£…ä¾èµ–
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶ä»£ç å’Œæ¨¡å‹
COPY . /app
COPY deploy/model.trt /app/deploy/

# æš´éœ²ç«¯å£
EXPOSE 8080

# å¯åŠ¨æœåŠ¡
CMD ["python", "tools/inference_server.py", "--config", "configs/deploy.yaml"]
```

#### Docker Compose

```yaml
version: '3.8'

services:
  bevfusion-e2e:
    build: .
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=0
      - MODEL_PATH=/app/deploy/model.trt
    ports:
      - "8080:8080"
    volumes:
      - ./data:/app/data:ro
      - ./output:/app/output
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

### æ–¹æ¡ˆ 2: Kubernetes éƒ¨ç½²

#### Deploymenté…ç½®

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bevfusion-e2e
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bevfusion-e2e
  template:
    metadata:
      labels:
        app: bevfusion-e2e
    spec:
      containers:
      - name: inference
        image: bevfusion-e2e:latest
        resources:
          limits:
            nvidia.com/gpu: 1
            memory: 32Gi
            cpu: 8
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: model-volume
          mountPath: /app/deploy
          readOnly: true
      volumes:
      - name: model-volume
        persistentVolumeClaim:
          claimName: model-pvc
```

#### Serviceé…ç½®

```yaml
apiVersion: v1
kind: Service
metadata:
  name: bevfusion-e2e-service
spec:
  selector:
    app: bevfusion-e2e
  ports:
  - protocol: TCP
    port: 80
    targetPort: 8080
  type: LoadBalancer
```

### æ–¹æ¡ˆ 3: NVIDIA Triton éƒ¨ç½²

#### æ¨¡å‹ä»“åº“ç»“æ„

```
model_repository/
â””â”€â”€ bevfusion_e2e/
    â”œâ”€â”€ config.pbtxt
    â”œâ”€â”€ 1/
    â”‚   â””â”€â”€ model.plan  # TensorRTå¼•æ“
    â””â”€â”€ labels.txt
```

#### config.pbtxt

```protobuf
name: "bevfusion_e2e"
platform: "tensorrt_plan"
max_batch_size: 4
input [
  {
    name: "images"
    data_type: TYPE_FP32
    dims: [ 6, 3, 256, 704 ]
  },
  {
    name: "points"
    data_type: TYPE_FP32
    dims: [ -1, 5 ]
  }
]
output [
  {
    name: "boxes_3d"
    data_type: TYPE_FP32
    dims: [ -1, 9 ]
  },
  {
    name: "seg_mask"
    data_type: TYPE_FP32
    dims: [ 4, 180, 180 ]
  }
]
instance_group [
  {
    count: 2
    kind: KIND_GPU
    gpus: [ 0 ]
  }
]
dynamic_batching {
  max_queue_delay_microseconds: 100
}
```

#### å¯åŠ¨TritonæœåŠ¡

```bash
docker run --gpus all --rm \
  -p 8000:8000 -p 8001:8001 -p 8002:8002 \
  -v $(pwd)/model_repository:/models \
  nvcr.io/nvidia/tritonserver:22.12-py3 \
  tritonserver --model-repository=/models
```

---

## ğŸŒ æ¨ç†æœåŠ¡

### REST API æœåŠ¡

åˆ›å»º `tools/inference_server.py`:

```python
from flask import Flask, request, jsonify, send_file
import torch
import numpy as np
import io
from PIL import Image
import base64

app = Flask(__name__)

# åŠ è½½æ¨¡å‹
model = load_model('configs/deploy.yaml', 'deploy/model.pth')
model.eval().cuda()

@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({'status': 'healthy', 'gpu': torch.cuda.is_available()})

@app.route('/predict', methods=['POST'])
def predict():
    """
    æ¥æ”¶å›¾åƒå’Œç‚¹äº‘æ•°æ®ï¼Œè¿”å›å¤šä»»åŠ¡æ„ŸçŸ¥ç»“æœ
    """
    data = request.json
    
    # è§£æè¾“å…¥
    images = decode_images(data['images'])  # List of 6 images
    points = np.array(data['points'])       # Point cloud
    
    # é¢„å¤„ç†
    processed = preprocess(images, points)
    
    # æ¨ç†
    with torch.no_grad():
        results = model(**processed)
    
    # åå¤„ç†
    output = postprocess(results[0])
    
    return jsonify({
        'detection': {
            'boxes': output['boxes_3d'].tolist(),
            'scores': output['scores_3d'].tolist(),
            'labels': output['labels_3d'].tolist()
        },
        'segmentation': {
            'mask': output['seg_mask'].tolist()
        },
        'tracking': {
            'ids': output['track_ids'].tolist() if output.get('track_ids') is not None else []
        }
    })

@app.route('/visualize', methods=['POST'])
def visualize():
    """
    ç”Ÿæˆå¯è§†åŒ–ç»“æœå¹¶è¿”å›å›¾åƒ
    """
    data = request.json
    
    # è¿è¡Œæ¨ç†
    images = decode_images(data['images'])
    points = np.array(data['points'])
    processed = preprocess(images, points)
    
    with torch.no_grad():
        results = model(**processed)
    
    # ç”Ÿæˆå¯è§†åŒ–
    vis_image = generate_visualization(results[0], images[0])
    
    # è½¬æ¢ä¸ºbytes
    img_io = io.BytesIO()
    vis_image.save(img_io, 'PNG')
    img_io.seek(0)
    
    return send_file(img_io, mimetype='image/png')

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080, threaded=True)
```

### gRPC æœåŠ¡

åˆ›å»º `proto/inference.proto`:

```protobuf
syntax = "proto3";

service BEVFusionE2E {
  rpc Predict(PredictRequest) returns (PredictResponse);
  rpc StreamPredict(stream PredictRequest) returns (stream PredictResponse);
}

message PredictRequest {
  repeated bytes images = 1;  // 6 images
  repeated float points = 2;   // Nx5 point cloud
  map<string, string> metadata = 3;
}

message PredictResponse {
  repeated BBox3D boxes = 1;
  SegmentationMask seg_mask = 2;
  repeated int32 track_ids = 3;
  repeated Trajectory trajectories = 4;
}

message BBox3D {
  float x = 1;
  float y = 2;
  float z = 3;
  float w = 4;
  float h = 5;
  float l = 6;
  float yaw = 7;
  float score = 8;
  int32 label = 9;
}

message SegmentationMask {
  repeated float data = 1;
  int32 height = 2;
  int32 width = 3;
  int32 channels = 4;
}

message Trajectory {
  repeated Point2D points = 1;
}

message Point2D {
  float x = 1;
  float y = 2;
}
```

### ROSèŠ‚ç‚¹éƒ¨ç½²

åˆ›å»º `ros/bevfusion_e2e_node.py`:

```python
#!/usr/bin/env python3
import rospy
from sensor_msgs.msg import Image, PointCloud2
from vision_msgs.msg import Detection3DArray
from nav_msgs.msg import OccupancyGrid
import torch

class BEVFusionE2ENode:
    def __init__(self):
        rospy.init_node('bevfusion_e2e_node')
        
        # åŠ è½½æ¨¡å‹
        self.model = self.load_model()
        
        # è®¢é˜…è¯é¢˜
        self.image_subs = []
        for i in range(6):
            sub = rospy.Subscriber(
                f'/camera_{i}/image_raw',
                Image,
                self.image_callback,
                callback_args=i
            )
            self.image_subs.append(sub)
        
        self.points_sub = rospy.Subscriber(
            '/lidar/points',
            PointCloud2,
            self.points_callback
        )
        
        # å‘å¸ƒè¯é¢˜
        self.detection_pub = rospy.Publisher(
            '/bevfusion/detections',
            Detection3DArray,
            queue_size=10
        )
        
        self.segmentation_pub = rospy.Publisher(
            '/bevfusion/segmentation',
            OccupancyGrid,
            queue_size=10
        )
        
        # æ•°æ®ç¼“å­˜
        self.images = [None] * 6
        self.points = None
        
    def load_model(self):
        model_path = rospy.get_param('~model_path', 'deploy/model.pth')
        config_path = rospy.get_param('~config_path', 'configs/deploy.yaml')
        
        model = load_model(config_path, model_path)
        model.eval().cuda()
        return model
    
    def image_callback(self, msg, camera_id):
        self.images[camera_id] = self.convert_image(msg)
        self.try_inference()
    
    def points_callback(self, msg):
        self.points = self.convert_points(msg)
        self.try_inference()
    
    def try_inference(self):
        # æ£€æŸ¥æ•°æ®æ˜¯å¦é½å…¨
        if None in self.images or self.points is None:
            return
        
        # è¿è¡Œæ¨ç†
        with torch.no_grad():
            results = self.model(
                img=torch.stack(self.images).unsqueeze(0).cuda(),
                points=self.points.unsqueeze(0).cuda()
            )
        
        # å‘å¸ƒç»“æœ
        self.publish_detection(results[0])
        self.publish_segmentation(results[0])
    
    def publish_detection(self, result):
        msg = Detection3DArray()
        # å¡«å……æ£€æµ‹ç»“æœ
        # ...
        self.detection_pub.publish(msg)
    
    def publish_segmentation(self, result):
        msg = OccupancyGrid()
        # å¡«å……åˆ†å‰²ç»“æœ
        # ...
        self.segmentation_pub.publish(msg)
    
    def run(self):
        rospy.spin()

if __name__ == '__main__':
    node = BEVFusionE2ENode()
    node.run()
```

---

## ğŸ“Š ç›‘æ§ä¸ç»´æŠ¤

### æ€§èƒ½ç›‘æ§

```python
import time
import psutil
import GPUtil

class PerformanceMonitor:
    def __init__(self):
        self.inference_times = []
        self.gpu_usage = []
        self.memory_usage = []
    
    def record_inference(self, start_time, end_time):
        inference_time = end_time - start_time
        self.inference_times.append(inference_time)
        
        # GPUä½¿ç”¨ç‡
        gpus = GPUtil.getGPUs()
        if gpus:
            self.gpu_usage.append(gpus[0].load * 100)
            self.memory_usage.append(gpus[0].memoryUsed)
    
    def get_stats(self):
        return {
            'avg_inference_time': np.mean(self.inference_times),
            'fps': 1.0 / np.mean(self.inference_times),
            'avg_gpu_usage': np.mean(self.gpu_usage),
            'avg_memory_usage': np.mean(self.memory_usage)
        }
```

### æ—¥å¿—è®°å½•

```python
import logging
from logging.handlers import RotatingFileHandler

def setup_logger(name, log_file, level=logging.INFO):
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    handler = RotatingFileHandler(
        log_file, 
        maxBytes=10*1024*1024,  # 10MB
        backupCount=5
    )
    handler.setFormatter(formatter)
    
    logger = logging.getLogger(name)
    logger.setLevel(level)
    logger.addHandler(handler)
    
    return logger

# ä½¿ç”¨
logger = setup_logger('bevfusion_e2e', 'logs/inference.log')
logger.info('Model loaded successfully')
logger.error('Inference failed', exc_info=True)
```

### å¥åº·æ£€æŸ¥

```python
class HealthChecker:
    def __init__(self, model):
        self.model = model
        self.last_check = time.time()
        self.check_interval = 60  # 60ç§’æ£€æŸ¥ä¸€æ¬¡
    
    def check(self):
        if time.time() - self.last_check < self.check_interval:
            return True
        
        try:
            # æµ‹è¯•æ¨ç†
            dummy_input = create_dummy_input()
            with torch.no_grad():
                _ = self.model(**dummy_input)
            
            self.last_check = time.time()
            return True
        
        except Exception as e:
            logger.error(f'Health check failed: {e}')
            return False
```

---

## ğŸ¯ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### éƒ¨ç½²å‰

- [ ] æ¨¡å‹è®­ç»ƒå®Œæˆå¹¶éªŒè¯
- [ ] æ¨¡å‹ä¼˜åŒ–ï¼ˆTensorRT/é‡åŒ–ï¼‰
- [ ] æ€§èƒ½åŸºå‡†æµ‹è¯•é€šè¿‡
- [ ] èµ„æºéœ€æ±‚è¯„ä¼°å®Œæˆ
- [ ] éƒ¨ç½²ç¯å¢ƒå‡†å¤‡å°±ç»ª

### éƒ¨ç½²ä¸­

- [ ] å®¹å™¨é•œåƒæ„å»ºæˆåŠŸ
- [ ] æ¨¡å‹æ–‡ä»¶æ­£ç¡®æŒ‚è½½
- [ ] ç½‘ç»œé…ç½®æ­£ç¡®
- [ ] GPUèµ„æºåˆ†é…æˆåŠŸ
- [ ] æœåŠ¡æˆåŠŸå¯åŠ¨

### éƒ¨ç½²å

- [ ] å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] æ€§èƒ½æŒ‡æ ‡è¾¾æ ‡
- [ ] æ—¥å¿—è®°å½•æ­£å¸¸
- [ ] ç›‘æ§ç³»ç»Ÿé…ç½®
- [ ] æ–‡æ¡£æ›´æ–°å®Œæˆ

---

## ğŸ“ˆ æ€§èƒ½åŸºå‡†

| éƒ¨ç½²æ–¹å¼ | å»¶è¿Ÿ | ååé‡ | GPUåˆ©ç”¨ç‡ | å†…å­˜å ç”¨ |
|---------|------|--------|-----------|----------|
| PyTorch FP32 | 80ms | 12.5 FPS | 85% | 12GB |
| PyTorch FP16 | 50ms | 20 FPS | 80% | 10GB |
| TensorRT FP16 | 30ms | 33 FPS | 75% | 8GB |
| TensorRT INT8 | 20ms | 50 FPS | 70% | 6GB |

*æµ‹è¯•ç¯å¢ƒ: NVIDIA RTX 3090*

---

**éƒ¨ç½²æ”¯æŒ**: è¯¦ç»†é—®é¢˜è¯·å‚è€ƒ[å®‰è£…æŒ‡å—](INSTALLATION_E2E.md)æˆ–æäº¤Issueã€‚
