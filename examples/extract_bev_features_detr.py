"""
BEVç‰¹å¾æå–å’ŒDETRæ£€æµ‹ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨BEVFusionDETRæ¨¡å‹æå–èåˆåçš„BEVç‰¹å¾å¹¶è¿›è¡Œæ£€æµ‹
"""
import torch
import numpy as np
from mmcv import Config
from mmdet3d.models import build_model
from mmdet3d.datasets import build_dataset, build_dataloader
import argparse
import os


def parse_args():
    parser = argparse.ArgumentParser(description='BEV Feature Extraction with DETR')
    parser.add_argument('config', help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('checkpoint', help='æ¨¡å‹checkpointè·¯å¾„')
    parser.add_argument('--out-dir', default='output/bev_features', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--device', default='cuda:0', help='ä½¿ç”¨çš„è®¾å¤‡')
    parser.add_argument('--save-features', action='store_true', help='æ˜¯å¦ä¿å­˜ç‰¹å¾')
    parser.add_argument('--visualize', action='store_true', help='æ˜¯å¦å¯è§†åŒ–')
    return parser.parse_args()


def load_model(config_path, checkpoint_path, device='cuda:0'):
    """
    åŠ è½½æ¨¡å‹
    
    Args:
        config_path (str): é…ç½®æ–‡ä»¶è·¯å¾„
        checkpoint_path (str): checkpointè·¯å¾„
        device (str): è®¾å¤‡
        
    Returns:
        model: åŠ è½½çš„æ¨¡å‹
        cfg: é…ç½®å¯¹è±¡
    """
    # åŠ è½½é…ç½®
    cfg = Config.fromfile(config_path)
    
    # æ„å»ºæ¨¡å‹
    model = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))
    
    # åŠ è½½checkpoint
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    if 'state_dict' in checkpoint:
        state_dict = checkpoint['state_dict']
    else:
        state_dict = checkpoint
    
    model.load_state_dict(state_dict, strict=False)
    model.to(device)
    model.eval()
    
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {checkpoint_path}")
    
    return model, cfg


def extract_bev_features(model, data, device='cuda:0'):
    """
    æå–BEVç‰¹å¾
    
    Args:
        model: BEVFusionDETRæ¨¡å‹
        data (dict): è¾“å…¥æ•°æ®
        device (str): è®¾å¤‡
        
    Returns:
        dict: BEVç‰¹å¾å­—å…¸
            - 'fused_bev': èåˆåçš„åŸå§‹BEVç‰¹å¾
            - 'processed_bev': å¤„ç†åçš„BEVç‰¹å¾
            - 'bev_flatten': å±•å¹³çš„BEVç‰¹å¾
            - 'position_encoding': ä½ç½®ç¼–ç 
    """
    with torch.no_grad():
        # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
        for key in data:
            if isinstance(data[key], torch.Tensor):
                data[key] = data[key].to(device)
        
        # æå–BEVç‰¹å¾
        bev_features = model.extract_bev_features_only(
            img=data['img'],
            points=data['points'],
            camera2ego=data['camera2ego'],
            lidar2ego=data['lidar2ego'],
            lidar2camera=data['lidar2camera'],
            lidar2image=data['lidar2image'],
            camera_intrinsics=data['camera_intrinsics'],
            camera2lidar=data['camera2lidar'],
            img_aug_matrix=data['img_aug_matrix'],
            lidar_aug_matrix=data['lidar_aug_matrix'],
            metas=data['img_metas'],
            depths=data.get('depths', None),
            radar=data.get('radar', None),
        )
    
    return bev_features


def run_detection(model, data, device='cuda:0'):
    """
    è¿è¡Œæ£€æµ‹
    
    Args:
        model: BEVFusionDETRæ¨¡å‹
        data (dict): è¾“å…¥æ•°æ®
        device (str): è®¾å¤‡
        
    Returns:
        list: æ£€æµ‹ç»“æœ
    """
    with torch.no_grad():
        # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
        for key in data:
            if isinstance(data[key], torch.Tensor):
                data[key] = data[key].to(device)
        
        # å‰å‘ä¼ æ’­
        results = model(**data)
    
    return results


def save_features(bev_features, save_path):
    """
    ä¿å­˜BEVç‰¹å¾
    
    Args:
        bev_features (dict): BEVç‰¹å¾å­—å…¸
        save_path (str): ä¿å­˜è·¯å¾„
    """
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # å°†tensorè½¬æ¢ä¸ºnumpy
    features_to_save = {}
    for key, value in bev_features.items():
        if isinstance(value, torch.Tensor):
            features_to_save[key] = value.cpu().numpy()
    
    # ä¿å­˜
    np.savez(save_path, **features_to_save)
    print(f"âœ… ç‰¹å¾å·²ä¿å­˜åˆ°: {save_path}")


def visualize_bev_features(bev_features, save_path=None):
    """
    å¯è§†åŒ–BEVç‰¹å¾
    
    Args:
        bev_features (dict): BEVç‰¹å¾å­—å…¸
        save_path (str): ä¿å­˜è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    import matplotlib.pyplot as plt
    
    # è·å–BEVç‰¹å¾
    bev_feat = bev_features['bev_features'][0].cpu().numpy()  # [C, H, W]
    
    # è®¡ç®—ç‰¹å¾çš„L2èŒƒæ•°ä½œä¸ºå¯è§†åŒ–
    feat_norm = np.linalg.norm(bev_feat, axis=0)  # [H, W]
    
    # ç»˜åˆ¶
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # åŸå§‹èåˆç‰¹å¾
    if 'fused_bev' in bev_features:
        fused_feat = bev_features['fused_bev'][0].cpu().numpy()
        fused_norm = np.linalg.norm(fused_feat, axis=0)
        axes[0].imshow(fused_norm, cmap='viridis')
        axes[0].set_title('Fused BEV Features')
        axes[0].axis('off')
    
    # å¤„ç†åçš„BEVç‰¹å¾
    axes[1].imshow(feat_norm, cmap='viridis')
    axes[1].set_title('Processed BEV Features')
    axes[1].axis('off')
    
    # ç‰¹å¾é€šé“çš„å‡å€¼
    feat_mean = np.mean(bev_feat, axis=0)
    axes[2].imshow(feat_mean, cmap='viridis')
    axes[2].set_title('BEV Features (Channel Mean)')
    axes[2].axis('off')
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    else:
        plt.show()
    
    plt.close()


def print_feature_info(bev_features):
    """
    æ‰“å°BEVç‰¹å¾ä¿¡æ¯
    
    Args:
        bev_features (dict): BEVç‰¹å¾å­—å…¸
    """
    print("\n" + "="*60)
    print("ğŸ“Š BEVç‰¹å¾ä¿¡æ¯")
    print("="*60)
    
    for key, value in bev_features.items():
        if isinstance(value, torch.Tensor):
            print(f"  {key:25s}: shape={list(value.shape)}, "
                  f"dtype={value.dtype}, device={value.device}")
            print(f"  {'':25s}  min={value.min().item():.4f}, "
                  f"max={value.max().item():.4f}, "
                  f"mean={value.mean().item():.4f}")
    
    print("="*60 + "\n")


def main():
    args = parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.out_dir, exist_ok=True)
    
    print("ğŸš€ å¼€å§‹BEVç‰¹å¾æå–...")
    
    # 1. åŠ è½½æ¨¡å‹
    print("\nğŸ“¥ åŠ è½½æ¨¡å‹...")
    model, cfg = load_model(args.config, args.checkpoint, args.device)
    
    # 2. å‡†å¤‡æ•°æ®ï¼ˆè¿™é‡Œä½¿ç”¨ç¬¬ä¸€ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹ï¼‰
    print("\nğŸ“¥ å‡†å¤‡æ•°æ®...")
    dataset = build_dataset(cfg.data.test)
    data_loader = build_dataloader(
        dataset,
        samples_per_gpu=1,
        workers_per_gpu=0,
        dist=False,
        shuffle=False
    )
    
    # 3. å¤„ç†æ•°æ®
    print("\nâš™ï¸  å¤„ç†æ•°æ®...")
    for i, data in enumerate(data_loader):
        print(f"\nå¤„ç†æ ·æœ¬ {i+1}/{len(data_loader)}")
        
        # æå–BEVç‰¹å¾
        print("  ğŸ” æå–BEVç‰¹å¾...")
        bev_features = extract_bev_features(model, data, args.device)
        
        # æ‰“å°ç‰¹å¾ä¿¡æ¯
        print_feature_info(bev_features)
        
        # è¿è¡Œæ£€æµ‹
        print("  ğŸ¯ è¿è¡Œæ£€æµ‹...")
        results = run_detection(model, data, args.device)
        print(f"  âœ… æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(results[0]['boxes_3d'])} ä¸ªç›®æ ‡")
        
        # ä¿å­˜ç‰¹å¾
        if args.save_features:
            save_path = os.path.join(args.out_dir, f'bev_features_{i:04d}.npz')
            save_features(bev_features, save_path)
        
        # å¯è§†åŒ–
        if args.visualize:
            vis_path = os.path.join(args.out_dir, f'bev_visualization_{i:04d}.png')
            visualize_bev_features(bev_features, vis_path)
        
        # åªå¤„ç†å‰å‡ ä¸ªæ ·æœ¬ä½œä¸ºç¤ºä¾‹
        if i >= 2:
            break
    
    print("\nâœ… å¤„ç†å®Œæˆï¼")
    print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {args.out_dir}")


if __name__ == '__main__':
    main()
