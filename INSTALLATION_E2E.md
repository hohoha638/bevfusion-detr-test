# BEVFusion ç«¯åˆ°ç«¯å¤šä»»åŠ¡æ„ŸçŸ¥ç³»ç»Ÿ - å®Œæ•´å®‰è£…æŒ‡å—

## ðŸ“‹ ç›®å½•

- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [çŽ¯å¢ƒå®‰è£…](#çŽ¯å¢ƒå®‰è£…)
- [æ•°æ®å‡†å¤‡](#æ•°æ®å‡†å¤‡)
- [æ¨¡åž‹é…ç½®](#æ¨¡åž‹é…ç½®)
- [éªŒè¯å®‰è£…](#éªŒè¯å®‰è£…)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)

---

## ðŸ–¥ï¸ ç³»ç»Ÿè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æœ€ä½Žé…ç½® | æŽ¨èé…ç½® |
|------|----------|----------|
| **GPU** | NVIDIA RTX 2080 Ti (11GB) | NVIDIA RTX 3090 (24GB) |
| **CPU** | 8æ ¸ | 16æ ¸+ |
| **å†…å­˜** | 32GB | 64GB+ |
| **å­˜å‚¨** | 200GB SSD | 500GB+ NVMe SSD |

### è½¯ä»¶è¦æ±‚

- **æ“ä½œç³»ç»Ÿ**: Ubuntu 18.04 / 20.04 / 22.04
- **CUDA**: 11.1 / 11.3 / 11.7
- **Python**: 3.8 / 3.9
- **PyTorch**: 1.9+ (æŽ¨è1.10.0)

---

## ðŸš€ çŽ¯å¢ƒå®‰è£…

### æ­¥éª¤ 1: åˆ›å»º Conda çŽ¯å¢ƒ

```bash
# åˆ›å»ºæ–°çŽ¯å¢ƒ
conda create -n bevfusion-e2e python=3.8 -y
conda activate bevfusion-e2e

# å®‰è£…PyTorch (æ ¹æ®CUDAç‰ˆæœ¬é€‰æ‹©)
# CUDA 11.3
conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge

# CUDA 11.1
# conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.1 -c pytorch -c conda-forge
```

### æ­¥éª¤ 2: å®‰è£… MMDetection3D ä¾èµ–

```bash
# å®‰è£… MMEngine
pip install openmim
mim install mmengine

# å®‰è£… MMCV
mim install "mmcv-full>=1.4.0,<1.7.0"

# å®‰è£… MMDetection
mim install "mmdet>=2.24.0,<3.0.0"

# å®‰è£… MMSegmentation (ç”¨äºŽåˆ†å‰²ä»»åŠ¡)
mim install "mmsegmentation>=0.20.0,<1.0.0"
```

### æ­¥éª¤ 3: å…‹éš†ä»“åº“

```bash
# å…‹éš†BEVFusionä»“åº“
git clone https://github.com/mit-han-lab/bevfusion.git
cd bevfusion

# æˆ–ä½¿ç”¨ä½ çš„å®šåˆ¶ç‰ˆæœ¬
# cd /path/to/your/bevfusion
```

### æ­¥éª¤ 4: å®‰è£…é¡¹ç›®ä¾èµ–

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install -r requirements.txt

# å®‰è£…é¢å¤–çš„ä¾èµ–ï¼ˆç«¯åˆ°ç«¯ç³»ç»Ÿéœ€è¦ï¼‰
pip install scipy scikit-learn matplotlib seaborn \
    opencv-python pillow tensorboard \
    numba nuscenes-devkit motmetrics
```

### æ­¥éª¤ 5: ç¼–è¯‘ CUDA æ‰©å±•

```bash
# ç¼–è¯‘è‡ªå®šä¹‰ç®—å­
cd mmdet3d/ops
python setup.py develop
cd ../..

# éªŒè¯ç¼–è¯‘
python -c "import mmdet3d; print(mmdet3d.__version__)"
```

### æ­¥éª¤ 6: å®‰è£…é¢å¤–å·¥å…·ï¼ˆå¯é€‰ä½†æŽ¨èï¼‰

```bash
# å¯è§†åŒ–å·¥å…·
pip install open3d mayavi vtk

# æ€§èƒ½åˆ†æž
pip install tensorboard wandb

# è§†é¢‘å¤„ç†
pip install imageio imageio-ffmpeg

# Jupyteræ”¯æŒ
pip install jupyter ipywidgets
```

---

## ðŸ“Š æ•°æ®å‡†å¤‡

### nuScenes æ•°æ®é›†

#### 1. ä¸‹è½½æ•°æ®

```bash
# åˆ›å»ºæ•°æ®ç›®å½•
mkdir -p data/nuscenes
cd data/nuscenes

# ä¸‹è½½æ•°æ®ï¼ˆéœ€è¦åœ¨ https://www.nuscenes.org/nuscenes æ³¨å†Œï¼‰
# ä¸‹è½½ä»¥ä¸‹æ–‡ä»¶ï¼š
# - Full dataset (v1.0): 
#   * Metadata (All)
#   * Sensor blobs (Camera, LiDAR, Radar)
# - Mini dataset (v1.0): ç”¨äºŽå¿«é€Ÿæµ‹è¯•

# ä½¿ç”¨wgetæˆ–å…¶ä»–å·¥å…·ä¸‹è½½
# wget <download_url>
```

#### 2. æ•°æ®ç»“æž„

ç¡®ä¿æ•°æ®æŒ‰ä»¥ä¸‹ç»“æž„ç»„ç»‡ï¼š

```
data/nuscenes/
â”œâ”€â”€ maps/                   # åœ°å›¾æ–‡ä»¶
â”œâ”€â”€ samples/                # å…³é”®å¸§æ•°æ®
â”‚   â”œâ”€â”€ CAM_FRONT/
â”‚   â”œâ”€â”€ CAM_FRONT_RIGHT/
â”‚   â”œâ”€â”€ CAM_FRONT_LEFT/
â”‚   â”œâ”€â”€ CAM_BACK/
â”‚   â”œâ”€â”€ CAM_BACK_LEFT/
â”‚   â”œâ”€â”€ CAM_BACK_RIGHT/
â”‚   â”œâ”€â”€ LIDAR_TOP/
â”‚   â””â”€â”€ RADAR_FRONT/
â”œâ”€â”€ sweeps/                 # ä¸­é—´å¸§æ•°æ®
â”‚   â”œâ”€â”€ CAM_FRONT/
â”‚   â”œâ”€â”€ ...
â”‚   â””â”€â”€ LIDAR_TOP/
â”œâ”€â”€ v1.0-trainval/         # æ ‡æ³¨å…ƒæ•°æ®
â”‚   â”œâ”€â”€ attribute.json
â”‚   â”œâ”€â”€ category.json
â”‚   â”œâ”€â”€ instance.json
â”‚   â”œâ”€â”€ scene.json
â”‚   â”œâ”€â”€ sample.json
â”‚   â””â”€â”€ ...
â””â”€â”€ v1.0-test/             # æµ‹è¯•é›†å…ƒæ•°æ®
```

#### 3. é¢„å¤„ç†æ•°æ®

```bash
# è¿”å›žé¡¹ç›®æ ¹ç›®å½•
cd ../..

# åˆ›å»ºæ•°æ®ä¿¡æ¯æ–‡ä»¶
python tools/create_data.py nuscenes \
    --root-path ./data/nuscenes \
    --out-dir ./data/nuscenes \
    --extra-tag nuscenes \
    --version v1.0-trainval

# ç”ŸæˆBEVåˆ†å‰²æ ‡æ³¨ï¼ˆç”¨äºŽè¯­ä¹‰åœ°å›¾ä»»åŠ¡ï¼‰
python tools/create_bev_seg_gt.py \
    --dataroot ./data/nuscenes \
    --version v1.0-trainval \
    --out-dir ./data/nuscenes/bev_seg
```

#### 4. éªŒè¯æ•°æ®

```bash
# æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
python tools/misc/browse_dataset.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    --show-interval 1
```

---

## âš™ï¸ æ¨¡åž‹é…ç½®

### 1. ä¸‹è½½é¢„è®­ç»ƒæƒé‡

```bash
# åˆ›å»ºé¢„è®­ç»ƒæ¨¡åž‹ç›®å½•
mkdir -p pretrained

# ä¸‹è½½ Swin Transformer é¢„è®­ç»ƒæƒé‡ï¼ˆCamera backboneï¼‰
wget https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_tiny_patch4_window7_224.pth \
    -O pretrained/swin_tiny_patch4_window7_224.pth

# ä¸‹è½½ BEVFusion é¢„è®­ç»ƒæ¨¡åž‹ï¼ˆå¯é€‰ï¼Œç”¨äºŽå¾®è°ƒï¼‰
# ä»Ž https://github.com/mit-han-lab/bevfusion ä¸‹è½½
```

### 2. é…ç½®æ–‡ä»¶æ£€æŸ¥

```bash
# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat configs/nuscenes/det/bevfusion-e2e-perception.yaml

# ç¡®ä¿ä»¥ä¸‹è·¯å¾„æ­£ç¡®ï¼š
# - data_root: data/nuscenes/
# - pretrained weightsè·¯å¾„
# - work_dir: è¾“å‡ºç›®å½•
```

### 3. ä¿®æ”¹é…ç½®ï¼ˆå¦‚éœ€è¦ï¼‰

ç¼–è¾‘ `configs/nuscenes/det/bevfusion-e2e-perception.yaml`:

```yaml
# æ ¹æ®ä½ çš„GPUè°ƒæ•´
data:
  samples_per_gpu: 2  # Batch size per GPU
  workers_per_gpu: 4  # DataLoader workers

# æ ¹æ®æ˜¾å­˜è°ƒæ•´
model:
  heads:
    perception:
      num_query_det: 600  # é™ä½Žqueryæ•°é‡èŠ‚çœæ˜¾å­˜
      num_query_seg: 50
```

---

## ðŸ‹ï¸ è®­ç»ƒæ¨¡åž‹

### å•GPUè®­ç»ƒ

```bash
python tools/train.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    --work-dir work_dirs/bevfusion_e2e_v1
```

### å¤šGPUè®­ç»ƒï¼ˆæŽ¨èï¼‰

```bash
# 4ä¸ªGPU
bash tools/dist_train.sh \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    4 \
    --work-dir work_dirs/bevfusion_e2e_v1

# 8ä¸ªGPU
bash tools/dist_train.sh \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    8 \
    --work-dir work_dirs/bevfusion_e2e_v1
```

### ä»Žæ£€æŸ¥ç‚¹æ¢å¤

```bash
bash tools/dist_train.sh \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    4 \
    --work-dir work_dirs/bevfusion_e2e_v1 \
    --resume-from work_dirs/bevfusion_e2e_v1/latest.pth
```

### ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹å¾®è°ƒ

```bash
bash tools/dist_train.sh \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    4 \
    --work-dir work_dirs/bevfusion_e2e_finetune \
    --load-from pretrained/bevfusion_pretrained.pth
```

---

## ðŸ” æ¨¡åž‹è¯„ä¼°

### å®Œæ•´è¯„ä¼°

```bash
# è¯„ä¼°æ‰€æœ‰ä»»åŠ¡
python tools/test.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --eval bbox segm tracking
```

### å•ä»»åŠ¡è¯„ä¼°

```bash
# ä»…è¯„ä¼°æ£€æµ‹
python tools/test.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --eval bbox

# ä»…è¯„ä¼°åˆ†å‰²
python tools/test.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --eval segm
```

---

## ðŸŽ¨ å¯è§†åŒ–æŽ¨ç†

### è¿è¡Œç«¯åˆ°ç«¯æŽ¨ç†å¹¶å¯è§†åŒ–

```bash
python examples/run_e2e_perception.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --out-dir output/visualization \
    --visualize \
    --save-results \
    --num-samples 20
```

### ç”Ÿæˆè§†é¢‘

```bash
python tools/visualize_video.py \
    --results output/visualization/results \
    --output output/video/perception.mp4 \
    --fps 10
```

---

## âœ… éªŒè¯å®‰è£…

### å¿«é€Ÿæµ‹è¯•

åˆ›å»ºæµ‹è¯•è„šæœ¬ `test_installation.py`:

```python
#!/usr/bin/env python3
import torch
import mmcv
import mmdet
import mmdet3d

print("=" * 60)
print("çŽ¯å¢ƒæ£€æŸ¥")
print("=" * 60)

# PyTorch
print(f"âœ“ PyTorch: {torch.__version__}")
print(f"âœ“ CUDA Available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"âœ“ CUDA Version: {torch.version.cuda}")
    print(f"âœ“ GPU Count: {torch.cuda.device_count()}")
    print(f"âœ“ GPU Name: {torch.cuda.get_device_name(0)}")

# MMCV
print(f"âœ“ MMCV: {mmcv.__version__}")

# MMDetection
print(f"âœ“ MMDetection: {mmdet.__version__}")

# MMDetection3D
print(f"âœ“ MMDetection3D: {mmdet3d.__version__}")

# æµ‹è¯•è‡ªå®šä¹‰ç®—å­
try:
    from mmdet3d.ops import Voxelization
    print("âœ“ Custom CUDA operators compiled successfully")
except:
    print("âœ— Custom CUDA operators not available")

# æµ‹è¯•æ¨¡åž‹æž„å»º
try:
    from mmcv import Config
    from mmdet3d.models import build_model
    
    cfg = Config.fromfile('configs/nuscenes/det/bevfusion-e2e-perception.yaml')
    model = build_model(cfg.model, train_cfg=None, test_cfg=cfg.get('test_cfg'))
    print("âœ“ Model build successful")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    dummy_img = torch.randn(1, 6, 3, 256, 704).cuda()
    dummy_points = torch.randn(1, 10000, 5).cuda()
    print("âœ“ Dummy data created")
    
except Exception as e:
    print(f"âœ— Model test failed: {e}")

print("=" * 60)
print("å®‰è£…éªŒè¯å®Œæˆï¼")
print("=" * 60)
```

è¿è¡Œæµ‹è¯•ï¼š

```bash
python test_installation.py
```

### æœ€å°ç¤ºä¾‹æµ‹è¯•

```bash
# ä½¿ç”¨miniæ•°æ®é›†å¿«é€Ÿæµ‹è¯•
python tools/test.py \
    configs/nuscenes/det/bevfusion-e2e-perception.yaml \
    work_dirs/bevfusion_e2e_v1/latest.pth \
    --eval bbox \
    --show-dir output/test_vis \
    --cfg-options data.test.ann_file=data/nuscenes/nuscenes_infos_val_mini.pkl
```

---

## ðŸ³ Docker éƒ¨ç½²ï¼ˆå¯é€‰ï¼‰

### æž„å»º Docker é•œåƒ

åˆ›å»º `Dockerfile`:

```dockerfile
FROM nvidia/cuda:11.3.1-cudnn8-devel-ubuntu20.04

ENV DEBIAN_FRONTEND=noninteractive
ENV CUDA_HOME=/usr/local/cuda

# å®‰è£…åŸºç¡€ä¾èµ–
RUN apt-get update && apt-get install -y \
    git wget curl vim \
    libglib2.0-0 libsm6 libxext6 libxrender-dev \
    python3-pip python3-dev \
    && rm -rf /var/lib/apt/lists/*

# å®‰è£…Miniconda
RUN wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh && \
    bash Miniconda3-latest-Linux-x86_64.sh -b -p /opt/conda && \
    rm Miniconda3-latest-Linux-x86_64.sh
ENV PATH=/opt/conda/bin:$PATH

# åˆ›å»ºçŽ¯å¢ƒ
RUN conda create -n bevfusion python=3.8 -y
SHELL ["conda", "run", "-n", "bevfusion", "/bin/bash", "-c"]

# å®‰è£…PyTorch
RUN conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch -c conda-forge

# å®‰è£…MMDetection3Dç›¸å…³
RUN pip install openmim && \
    mim install mmengine && \
    mim install "mmcv-full>=1.4.0,<1.7.0" && \
    mim install "mmdet>=2.24.0,<3.0.0" && \
    mim install "mmsegmentation>=0.20.0,<1.0.0"

# å¤åˆ¶é¡¹ç›®
WORKDIR /workspace
COPY . /workspace/bevfusion

# å®‰è£…ä¾èµ–
RUN cd bevfusion && \
    pip install -r requirements.txt && \
    cd mmdet3d/ops && python setup.py develop

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /workspace/bevfusion

CMD ["/bin/bash"]
```

æž„å»ºå’Œè¿è¡Œï¼š

```bash
# æž„å»ºé•œåƒ
docker build -t bevfusion-e2e:latest .

# è¿è¡Œå®¹å™¨
docker run --gpus all -it --rm \
    -v /path/to/data:/workspace/bevfusion/data \
    -v /path/to/output:/workspace/bevfusion/output \
    bevfusion-e2e:latest
```

---

## â“ å¸¸è§é—®é¢˜

### Q1: CUDA out of memory

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# é™ä½Žbatch size
data:
  samples_per_gpu: 1

# é™ä½Žqueryæ•°é‡
model:
  heads:
    perception:
      num_query_det: 300
      num_query_seg: 30
```

### Q2: ç¼–è¯‘CUDAæ‰©å±•å¤±è´¥

**è§£å†³æ–¹æ¡ˆ**:
```bash
# ç¡®ä¿CUDAç‰ˆæœ¬åŒ¹é…
nvcc --version
python -c "import torch; print(torch.version.cuda)"

# æ¸…ç†é‡æ–°ç¼–è¯‘
cd mmdet3d/ops
rm -rf build/
python setup.py clean
python setup.py develop
```

### Q3: æ•°æ®åŠ è½½æ…¢

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# å¢žåŠ workers
data:
  workers_per_gpu: 8

# ä½¿ç”¨SSDå­˜å‚¨æ•°æ®
# å¯ç”¨é¢„åŠ è½½
data:
  train:
    dataset:
      pipeline:
        - type: LoadMultiViewImageFromFiles
          to_float32: true
          prefetch: true
```

### Q4: è®­ç»ƒä¸ç¨³å®š

**è§£å†³æ–¹æ¡ˆ**:
```yaml
# é™ä½Žå­¦ä¹ çŽ‡
optimizer:
  lr: 1.0e-4

# å¢žåŠ warmup
lr_config:
  warmup_iters: 1000

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
optimizer_config:
  grad_clip:
    max_norm: 10
```

### Q5: å¯è§†åŒ–ç»“æžœä¸æ˜¾ç¤º

**è§£å†³æ–¹æ¡ˆ**:
```bash
# å®‰è£…æ˜¾ç¤ºä¾èµ–
pip install opencv-python-headless matplotlib

# ä½¿ç”¨ä¿å­˜è€Œéžæ˜¾ç¤º
python examples/run_e2e_perception.py ... --save-results
```

---

## ðŸ“ æ£€æŸ¥æ¸…å•

å®‰è£…å®ŒæˆåŽï¼Œç¡®ä¿ä»¥ä¸‹æ‰€æœ‰é¡¹éƒ½å·²å®Œæˆï¼š

- [ ] CUDAå’ŒPyTorchæ­£ç¡®å®‰è£…
- [ ] MMDetection3DåŠä¾èµ–å®‰è£…
- [ ] CUDAæ‰©å±•ç¼–è¯‘æˆåŠŸ
- [ ] nuScenesæ•°æ®é›†ä¸‹è½½å¹¶ç»„ç»‡
- [ ] æ•°æ®é¢„å¤„ç†å®Œæˆ
- [ ] é…ç½®æ–‡ä»¶æ£€æŸ¥æ— è¯¯
- [ ] æ¨¡åž‹å¯ä»¥æˆåŠŸæž„å»º
- [ ] è®­ç»ƒè„šæœ¬å¯ä»¥è¿è¡Œ
- [ ] æŽ¨ç†è„šæœ¬å¯ä»¥è¿è¡Œ
- [ ] å¯è§†åŒ–ç»“æžœæ­£å¸¸ç”Ÿæˆ

---

## ðŸŽ‰ ä¸‹ä¸€æ­¥

å®‰è£…å®ŒæˆåŽï¼Œä½ å¯ä»¥ï¼š

1. **è®­ç»ƒæ¨¡åž‹**: æŒ‰ç…§è®­ç»ƒæŒ‡å—å¼€å§‹è®­ç»ƒ
2. **è¿è¡ŒæŽ¨ç†**: ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹è¿›è¡ŒæŽ¨ç†
3. **å¯è§†åŒ–ç»“æžœ**: ç”Ÿæˆå¤šä»»åŠ¡æ„ŸçŸ¥å¯è§†åŒ–
4. **æ€§èƒ½ä¼˜åŒ–**: æ ¹æ®ç¡¬ä»¶è°ƒæ•´é…ç½®

å‚è€ƒå…¶ä»–æ–‡æ¡£èŽ·å–æ›´å¤šä¿¡æ¯ï¼š
- [ä½¿ç”¨æŒ‡å—](docs/E2E_PERCEPTION_GUIDE.md)
- [éƒ¨ç½²æ–¹æ¡ˆ](DEPLOYMENT_E2E.md)
- [å¯è§†åŒ–å·¥å…·](tools/visualize_e2e.py)

---

**å®‰è£…æ”¯æŒ**: å¦‚é‡é—®é¢˜ï¼Œè¯·æŸ¥çœ‹[å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)æˆ–æäº¤Issueã€‚
